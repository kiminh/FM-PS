一、worker端的函数实现

#动态构建神经网络保存到self.network
#以及建立self.parameters和self.gradient的映射(key->对应shape和data_type的ndarray)
def set_training_env(self):
  #建立层
  layer_list = []
  for layer in self.task.layers:
    #对于每一层需要做两件事
    #一是动态建立网络层对象
    #而是保存其中的参数key,shape,data_type建立key->value(ndarray)的工作
    #两个映射,一个是为了接收来自server的参数值，能够替换当前网络的所有参数
    #二是要建立梯度，即push的内容
    name = layer.name
    #TODO
    if name == "Input":
      #对于输入层来说，只需要知道输入的shape
      pass
    #TODO 可以抽象出一个函数
    elif name == "Dense":
      #要构建全连接层只需要知道输出size和激活函数
      activation = layer.activation
      output_size = None
      #参数列表
      for parameter in layer.parameter_list:
        parameter_name = parameter.name
        #TODOdata_type
        parameter_shape = parameter.shape
        #建立参数和梯度的空数组
        self.gradient[parameter_name] = np.zeros(shape)
        self.parameters[parameter_name] = np.zeros(shape)
        #对于全连接层的output_size
        #TODO目前是二维
        if parameter.dim == 2:
          output_size = parameter_shape[1]
      layer_list.append(FullConnected(output_size, activation))
  #所有层都添加后就可以建立网络对象
  self.network = Network(layer_list)

#根据self.server_group中的信息建立一个客户端组
#TODO思考如何确保连接是稳定且符合预期
def connect_to_server(self):
  #该函数的关键仍然在于确保与每一个server只建立一次客户端并且成功的连接
  #拿到应该建立的服务器组信息
  self.server_group = self.task.servers
  #如果客户端列表个数已经建立了对应的客户端那么就退出
  if len(self.parameter_client_list) == len(self.server_group):
    return
  for rank in range(len(server_group)):
    #建立客户端
    transport = TSocket.TSocket(server_group[rank].ip, server_group[rank].port)
    transport = TTransport.TBufferedTransport(transport)
    protocol = TBinaryProtocol.TBinaryProtocol(transport)
    self.parameter_client_list.append(ParameterServer.Client(protocol))
    transport.open()

  
#key operation
#通过客户端组向server group请求第t轮的参数
#需要做一个整理到self.parameter
def pull_parameter(self,t):
  serialized_parameter_list = []
  #对于每一个客户端都会拉回若干参数，需要将参数按key整理
  #先添加再整理
  for client in self.parameter_client_list:
    serialized_part_parameter = client.pull(t)
    serialized_parameter_list.appen(serialized_part_parameter)
  #每一个服务器都会返回一个序列化后的dict
  for part_parameter in serialized_parameter_list:
    pass
    #TODO
    #反序列化为一个protobuf对象
    #TODO定义该对象结构
    """
    protobuf_object = Object()
    protobuf_object.ParseFromString(part_parameter)
    #按key遍历
    for key in protobuf_object:
      value = ...
      #fit value into self.parameters
    """

#@para无
#return 任务信息WorkerTask（内含一组需要连接的服务器）
#需要保存到self.task以及self.server_group
def ask_for_task(self):
#循环请求任务，若任务为空则继续请求
#TODO讨论,需要有什么措施吗，还是一直请求到有任务
  while True:
    #请求任务
    task = self.master_client.worker_ask_for_task()
    #任务包括什么：服务器信息+训练任务
    #目前想法：只要字节流长度大于0就看作有任务
    #判断任务
    if len(task) <= 0:
      continue
    #解析任务
    if not self.task.ParseFromString(task):
      logger.error("反序列化任务失败")
    if self.task.HasField('dataset'):
      logger.info("收到任务中的数据集为"+self.task.dataset)
    if self.task.HasField('data_path'):
      logger.info("收到任务中的数据路径为"+self.task.data_path)
    #判断任务
    break

二、server端的参数加载和赋值
//对于每一个参数构建一个对象（vector 或者矩阵）
//进行初始化，建立这个映射
void Pserver::load_parameter_to_memory(){
  //TODO,目前默认初始化为随机初始化
  float upper_bound = 1.0;
  float lower_bound = 0.0;
  for(int i = 0; i < server_task_.parameter_list.size(); i++){
    const task::Parameter& parameter = server_task_.parameter_list(i);
    //根据dim判断类型
    //随机赋值后加入哈希表
    if(1 == parameter.dim()){
      shared_ptr<VectorParameter> value 
          = make_shared<VectorParameter>(parameter.data_type(), {parameter.shape(0)});
      value->set_random(upper_bound, lower_bound);
      parameter_[parameter.key()] = value;
    }
    else if(2 == parameter.dim()){
      shared_ptr<MatrixParameter> value 
        = make_shared<MatrixParameter>(parameter.data_type(), {parameter.shape(0), parameter.shape(1)});
      value->set_random(upper_bound,lower_bound);
      parameter_[parameter.key()] = value;
    }
  }
}

三、优化器接口
class SgdOptimizer{
 public:

  SgdOptimizer();

  void update(std::shared_ptr<ParameterValue> parameter,
                             std::shared_ptr<ParameterValue> gradient, float learning_rate);
};


四、设计参数传递的protobuf
worker和server之间的参数传递

message ParametersOrGradients{
  repeated KeyValuePair pairs = 1;
}

message KeyValuePair{
  optional uint32 dim = 1;
  repeated uint32 shape = 2;
  //连续的value, 接收方需要根据shape来解析
  repeated float values = 3;
  //TODO:data_type
};

